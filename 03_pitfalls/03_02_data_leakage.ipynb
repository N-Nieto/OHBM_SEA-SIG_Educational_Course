{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cb21af",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/N-Nieto/OHBM_SEA-SIG_Educational_Course/blob/master/03_pitfalls/03_02_data_leakage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbb10f",
   "metadata": {},
   "source": [
    "# Leakage exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa86bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data shape: (588, 122)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "# Features: Cortical + Subcortical\n",
    "features = [\"cortical\", \"subcortical\"]\n",
    "\n",
    "# Target: Sex\n",
    "target = [\"SEX_ID (1=m, 2=f)\"]\n",
    "# Confounding variables: No for this example\n",
    "confounding = []\n",
    "\n",
    "data_path = Path(\"../data/\")\n",
    "df_data = pd.read_csv(data_path / \"cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "columns_features = []\n",
    "for feature in features:\n",
    "    if feature == \"cortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path / \"cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    elif feature == \"subcortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path\n",
    "            / \"cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    else:\n",
    "        print(\"feature not recognized\")\n",
    "\n",
    "    df_data = df_data.join(df_feature, how=\"inner\")\n",
    "    columns_features = columns_features + df_feature.columns.to_list()\n",
    "\n",
    "\n",
    "print(f\"Initial data shape: {df_data.shape}\")\n",
    "\n",
    "# Check for NaNs in confounding columns\n",
    "confounding_cols = target + confounding\n",
    "for col in confounding_cols:\n",
    "    if df_data[col].isna().sum() > 0:\n",
    "        print(f\"{df_data[col].isna().sum()} NaNs in column {col}.\")\n",
    "        print(\"Drop NaNs and align subjects\")\n",
    "\n",
    "        # Drop NaNs from the brain dataframe (which contains all columns)\n",
    "        df_data = df_data.dropna(subset=[col])\n",
    "        print(f\"New data shape: {df_data.shape}\")\n",
    "    else:\n",
    "        print(f\"No NaNs in column {col}.\")\n",
    "\n",
    "print(f\"Final data shape: {df_data.shape}\")\n",
    "\n",
    "y = df_data[target].values.ravel()\n",
    "if target == [\"SEX_ID (1=m, 2=f)\"]:\n",
    "    y = np.where(y == 2, 0, 1)  # 1\n",
    "\n",
    "\n",
    "X = df_data.loc[:, columns_features].values  # only brain features\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "601588fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "random_state = 50\n",
    "test_size = 0.3\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, shuffle=True, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2df8ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"SEX_ID (1=m, 2=f)\"].value_counts()  # the classes look reasonably balanced\n",
    "\n",
    "\n",
    "# random samply majority class to have balanced classes\n",
    "def random_undersample(X, y, random_state=42):\n",
    "    # Find the indices of each class\n",
    "    class_0_indices = np.where(y == 1)[0]\n",
    "    class_1_indices = np.where(y == 2)[0]\n",
    "\n",
    "    # Determine the size of the minority class\n",
    "    min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
    "\n",
    "    # Randomly sample from each class to match the minority class size\n",
    "    np.random.seed(random_state)\n",
    "    sampled_class_0_indices = np.random.choice(\n",
    "        class_0_indices, min_class_size, replace=False\n",
    "    )\n",
    "    sampled_class_1_indices = np.random.choice(\n",
    "        class_1_indices, min_class_size, replace=False\n",
    "    )\n",
    "\n",
    "    # Combine the sampled indices and shuffle them\n",
    "    combined_indices = np.concatenate(\n",
    "        (sampled_class_0_indices, sampled_class_1_indices)\n",
    "    )\n",
    "    np.random.shuffle(combined_indices)\n",
    "\n",
    "    # Return the undersampled X and y\n",
    "    return X[combined_indices], y[combined_indices]\n",
    "\n",
    "\n",
    "X, y = random_undersample(X, y, random_state=random_state)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, shuffle=True, random_state=random_state\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07149055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (588, 116)\n",
      "y shape (588,)\n",
      "X_train shape (411, 116)\n",
      "X_test shape (177, 116)\n",
      "y_train shape (411,)\n",
      "y_test shape (177,)\n"
     ]
    }
   ],
   "source": [
    "# Check size of data\n",
    "print(\"X shape\", X.shape)\n",
    "print(\"y shape\", y.shape)\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcc305",
   "metadata": {},
   "source": [
    "#  Leakage example 1:\n",
    "### Train on whole data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91d5d666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Train accuracy: 0.9795918367346939\n",
      "Raw Data - Test accuracy: 0.9830508474576272\n"
     ]
    }
   ],
   "source": [
    "# Train our model on the whole data (Fig. 2 in Sasse et al., 2025)\n",
    "dt_raw_lkg1 = DecisionTreeClassifier(max_depth=10, random_state=random_state)\n",
    "dt_raw_lkg1.fit(X, y)\n",
    "\n",
    "print(\"Raw Data - Train accuracy:\", dt_raw_lkg1.score(X, y))\n",
    "print(\"Raw Data - Test accuracy:\", dt_raw_lkg1.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466d8c2",
   "metadata": {},
   "source": [
    "### Correct procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c417001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Train accuracy: 0.9829683698296837\n",
      "Raw Data - Test accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Train our model on the train set and test on the test set\n",
    "dt_raw = DecisionTreeClassifier(max_depth=10, random_state=random_state)\n",
    "dt_raw.fit(X_train, y_train)\n",
    "\n",
    "print(\"Raw Data - Train accuracy:\", dt_raw.score(X_train, y_train))\n",
    "print(\"Raw Data - Test accuracy:\", dt_raw.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089d942",
   "metadata": {},
   "source": [
    "When the model was trained in train set and tested on test set the test performance dropped.\n",
    "When the model was trained in the whole dataset it performed well in both, train and test datasets. \n",
    "This is because the model learned patterns of the test set during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92059b32",
   "metadata": {},
   "source": [
    "# Leakage example 2:\n",
    "### Feature selection on whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13a95ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reproducible cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# ========== Case 1: Data Leakage ==========\n",
    "# Feature selection on entire dataset (leakage)\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_selected_leak = selector.fit_transform(X, y)\n",
    "\n",
    "# Scale and reduce dimensionality on entire dataset (leakage)\n",
    "scaler = StandardScaler()\n",
    "X_scaled_leak = scaler.fit_transform(X_selected_leak)\n",
    "\n",
    "# Evaluate using fixed CV\n",
    "model = RidgeClassifierCV()\n",
    "scores_leakage = []\n",
    "for train, test in cv.split(X, y):\n",
    "    model.fit(X_scaled_leak[train, :], y[train])\n",
    "    pred = model.predict(X_scaled_leak[test, :])\n",
    "    scores_leakage.append(roc_auc_score(y[test], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b6b48",
   "metadata": {},
   "source": [
    "### Correct procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Case 2: No Leakage ==========\n",
    "# Pipeline with feature selection inside each fold\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "scaler = StandardScaler()\n",
    "model = RidgeClassifierCV()\n",
    "scores_no_leakage = []\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train, :]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test, :]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    # Scale and reduce dimensionality on entire dataset (leakage)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit feature selector\n",
    "    X_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Fit ML model\n",
    "    model.fit(X_selected, y_train)\n",
    "\n",
    "    pred = model.predict(X_test_selected)\n",
    "    scores_no_leakage.append(roc_auc_score(y[test], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a4817ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fold  Accuracy with Leakage  Accuracy without Leakage  Difference\n",
      "0     1               0.733974                  0.733974    0.000000\n",
      "1     2               0.722902                  0.715326    0.007576\n",
      "2     3               0.757867                  0.757867    0.000000\n",
      "3     4               0.813462                  0.813462    0.000000\n",
      "4     5               0.717308                  0.738462   -0.021154\n",
      "\n",
      "Mean Accuracy with Leakage:  0.7491\n",
      "Mean Accuracy without Leakage:  0.7518\n",
      "Mean Difference:  -0.0027\n"
     ]
    }
   ],
   "source": [
    "# ========== Compare Results ==========\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Fold\": np.arange(1, 6),\n",
    "        \"Accuracy with Leakage\": scores_leakage,\n",
    "        \"Accuracy without Leakage\": scores_no_leakage,\n",
    "        \"Difference\": np.array(scores_leakage) - np.array(scores_no_leakage),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results_df)\n",
    "print(\"\\nMean Accuracy with Leakage: \", round(np.mean(scores_leakage), 4))\n",
    "print(\"Mean Accuracy without Leakage: \", round(np.mean(scores_no_leakage), 4))\n",
    "print(\"Mean Difference: \", round(np.mean(results_df[\"Difference\"]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619964c3",
   "metadata": {},
   "source": [
    "The approach causing leakage generally yielded better performance than the correct approach. Even though in this example the effect of leakage is not huge, in bigger and complex datasets its effect is much severe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19ac4d",
   "metadata": {},
   "source": [
    "It is important to note that the results and the effect of leakage might change based on the use of different models, seeds, samples, features, etc.\n",
    "Also leakage is complex and it is often unclear where it might or might not show. However, it is always important to avoid it in order to yield valid estimations of model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FZJ_collaborations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cb21af",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/N-Nieto/OHBM_SEA-SIG_Educational_Course/blob/master/03_pitfalls/03_02_data_leakage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e708f",
   "metadata": {},
   "source": [
    "### If you are running in Google Colab, uncomment the cell below to load the data.\n",
    "### If you are running locally, ignore the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1432ea",
   "metadata": {},
   "source": [
    "For questions on this notebook contact: n.nieto@fz-juelich.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from urllib.request import urlretrieve\n",
    "# # Clean files\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Download necessary data files\n",
    "# Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# # 01_basic_ML.ipynb needs this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_IXI_behavioural.csv?download=1', './data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # 02_XAI.ipynb needs also this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# # Load data\n",
    "# df_behav = pd.read_csv(\"data/cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "\n",
    "# # Some height values are not sensible, we filter them out\n",
    "# height = df_behav[\"HEIGHT\"].values\n",
    "# df_behav = df_behav[np.logical_and(height > 120, height < 200)]\n",
    "\n",
    "# # Remove NaNs and duplicates\n",
    "# df_behav.dropna(inplace=True)\n",
    "# df_behav.drop_duplicates(keep='first', inplace=True)\n",
    "# df_behav.to_csv('data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_cortical_100 = pd.read_csv(\"data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\", index_col=0)\n",
    "# df_cortical_100.dropna(inplace=True)\n",
    "# df_cortical_100.to_csv('data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_subcortical = pd.read_csv(\"data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\", index_col=0)\n",
    "# df_subcortical.dropna(inplace=True)\n",
    "# df_subcortical.to_csv('data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# data_path = Path(\"data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbb10f",
   "metadata": {},
   "source": [
    "# Leakage exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "if 'data_path' not in locals():\n",
    "    data_path = Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cc841",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa86bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data shape: (533, 122)\n",
      "X shape\n",
      "(533, 116)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "# Features: Cortical + Subcortical\n",
    "features = [\"cortical\", \"subcortical\"]\n",
    "\n",
    "# Target: Sex\n",
    "target = [\"SEX_ID (1=m, 2=f)\"]\n",
    "# Confounding variables: No for this example\n",
    "confounding = []\n",
    "\n",
    "df_data = pd.read_csv(data_path / \"cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "columns_features = []\n",
    "for feature in features:\n",
    "    if feature == \"cortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path / \"cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    elif feature == \"subcortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path\n",
    "            / \"cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    else:\n",
    "        print(\"feature not recognized\")\n",
    "\n",
    "    df_data = df_data.join(df_feature, how=\"inner\")\n",
    "    columns_features = columns_features + df_feature.columns.to_list()\n",
    "\n",
    "print(f\"Final data shape: {df_data.shape}\")\n",
    "\n",
    "y = df_data[target].values.ravel()\n",
    "if target == [\"SEX_ID (1=m, 2=f)\"]:\n",
    "    y = np.where(y == 2, 0, 1)  # Put the classes as 0 and 1\n",
    "\n",
    "X = df_data.loc[:, columns_features].values  # only brain features\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2df8ef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (533, 116)\n",
      "y shape (533,)\n",
      "X_train shape (373, 116)\n",
      "X_test shape (160, 116)\n",
      "y_train shape (373,)\n",
      "y_test shape (160,)\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "random_state = 42\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, shuffle=True, random_state=random_state\n",
    ")\n",
    "# Check size of data\n",
    "print(\"X shape\", X.shape)\n",
    "print(\"y shape\", y.shape)\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcc305",
   "metadata": {},
   "source": [
    "#  Leakage example 1:\n",
    "### Train on whole data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5d666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Train AUC: 1.0\n",
      "Raw Data - Test AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train our model on the whole data (Fig. 2 in Sasse et al., 2025)\n",
    "model = RandomForestClassifier(max_depth=10, random_state=random_state)\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Raw Data - Train AUC:\", accuracy_score(model.predict(X), y))          # Train on the whole data! Very bad!\n",
    "print(\"Raw Data - Test AUC:\", accuracy_score(model.predict(X_test), y_test)) # Test data belongs to the X!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466d8c2",
   "metadata": {},
   "source": [
    "### Correct procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c417001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data - Train accuracy: 1.0\n",
      "Raw Data - Test accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "# Train our model on the train set and test on the test set\n",
    "model = RandomForestClassifier(max_depth=10, random_state=random_state)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Raw Data - Train accuracy:\", accuracy_score(model.predict(X_train), y_train))\n",
    "print(\"Raw Data - Test accuracy:\", accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089d942",
   "metadata": {},
   "source": [
    "When the model was trained in train set and tested on test set the test performance dropped.\n",
    "When the model was trained in the whole dataset it performed well in both, train and test datasets. \n",
    "This is because the model learned patterns of the test set during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92059b32",
   "metadata": {},
   "source": [
    "# Leakage example 2:\n",
    "### Feature selection on whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13a95ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define reproducible cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Preprocess the whole data (leakage)\n",
    "n_components = 7\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X.copy(), y)\n",
    "\n",
    "# Scale the entire dataset (leakage)\n",
    "scaler = StandardScaler()\n",
    "X_pca_scaled = scaler.fit_transform(X_pca)\n",
    "\n",
    "# Evaluate using fixed CV\n",
    "model = DecisionTreeClassifier(max_depth=10, random_state=random_state)\n",
    "scores_leakage = []\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    model.fit(X_pca_scaled[train, :], y[train])\n",
    "    pred = model.predict(X_pca_scaled[test, :])\n",
    "    scores_leakage.append(roc_auc_score(y[test], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b6b48",
   "metadata": {},
   "source": [
    "### Correct procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f99d7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with feature selection inside each fold\n",
    "pca = PCA(n_components=n_components)\n",
    "scaler = StandardScaler()\n",
    "model = DecisionTreeClassifier(max_depth=10, random_state=random_state)\n",
    "\n",
    "scores_no_leakage = []\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train, :]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test, :]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Fit feature selector\n",
    "    X_train = pca.fit_transform(X_train, y_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "    # Scale and reduce dimensionality on entire dataset (leakage)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit ML model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    scores_no_leakage.append(roc_auc_score(y[test], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a4817ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fold  Accuracy with Leakage  Accuracy without Leakage  Difference\n",
      "0     1               0.734397                  0.635816    0.098582\n",
      "1     2               0.702482                  0.559929    0.142553\n",
      "2     3               0.682733                  0.644244    0.038489\n",
      "3     4               0.622070                  0.687883   -0.065813\n",
      "4     5               0.674901                  0.643166    0.031735\n",
      "\n",
      "Mean Accuracy with Leakage:  68.3317\n",
      "Mean Accuracy without Leakage:  63.4208\n",
      "Mean Difference:  0.0491\n"
     ]
    }
   ],
   "source": [
    "# ========== Compare Results ==========\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Fold\": np.arange(1, 6),\n",
    "        \"Accuracy with Leakage\": scores_leakage,\n",
    "        \"Accuracy without Leakage\": scores_no_leakage,\n",
    "        \"Difference\": np.array(scores_leakage) - np.array(scores_no_leakage),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results_df)\n",
    "print(\"\\nMean Accuracy with Leakage: \", round(np.mean(scores_leakage)*100, 4))\n",
    "print(\"Mean Accuracy without Leakage: \", round(np.mean(scores_no_leakage)*100, 4))\n",
    "print(\"Mean Difference: \", round(np.mean(results_df[\"Difference\"]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619964c3",
   "metadata": {},
   "source": [
    "The approach causing leakage generally yielded better performance than the correct approach. Even though in this example the effect of leakage is not huge, in bigger and complex datasets its effect is much severe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19ac4d",
   "metadata": {},
   "source": [
    "It is important to note that the results and the effect of leakage might change based on the use of different models, seeds, samples size, features number and distribution, linear or non-linear signal, amount of noise, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3666b",
   "metadata": {},
   "source": [
    "# To do!\n",
    "Lets try another model, another pre-processing, or even random seeds to see the effect of the data leakage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FZJ_collaborations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cb21af",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/N-Nieto/OHBM_SEA-SIG_Educational_Course/blob/master/03_pitfalls/03_02_data_leakage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e708f",
   "metadata": {},
   "source": [
    "### If you are running in Google Colab, uncomment the cell bellow to load the data.\n",
    "### If you are running locally, ignore the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from urllib.request import urlretrieve\n",
    "# # Clean files\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Download necessary data files\n",
    "# Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# # 01_basic_ML.ipynb needs this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_IXI_behavioural.csv?download=1', './data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # 02_XAI.ipynb needs also this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# # Load data\n",
    "# df_behav = pd.read_csv(\"data/cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "\n",
    "# # Some height values are not sensible, we filter them out\n",
    "# height = df_behav[\"HEIGHT\"].values\n",
    "# df_behav = df_behav[np.logical_and(height > 120, height < 200)]\n",
    "\n",
    "# # Remove NaNs and duplicates\n",
    "# df_behav.dropna(inplace=True)\n",
    "# df_behav.drop_duplicates(keep='first', inplace=True)\n",
    "# df_behav.to_csv('data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_cortical_100 = pd.read_csv(\"data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\", index_col=0)\n",
    "# df_cortical_100.dropna(inplace=True)\n",
    "# df_cortical_100.to_csv('data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_subcortical = pd.read_csv(\"data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\", index_col=0)\n",
    "# df_subcortical.dropna(inplace=True)\n",
    "# df_subcortical.to_csv('data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# data_path = Path(\"data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbb10f",
   "metadata": {},
   "source": [
    "# Leakage exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "if 'data_path' not in locals():\n",
    "    data_path = Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa86bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Features: Cortical + Subcortical\n",
    "features = [\"cortical\", \"subcortical\"]\n",
    "\n",
    "# Target: Sex\n",
    "target = [\"SEX_ID (1=m, 2=f)\"]\n",
    "# Confounding variables: No for this example\n",
    "confounding = []\n",
    "\n",
    "df_data = pd.read_csv(data_path / \"cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "columns_features = []\n",
    "for feature in features:\n",
    "    if feature == \"cortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path / \"cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    elif feature == \"subcortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path\n",
    "            / \"cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    else:\n",
    "        print(\"feature not recognized\")\n",
    "\n",
    "    df_data = df_data.join(df_feature, how=\"inner\")\n",
    "    columns_features = columns_features + df_feature.columns.to_list()\n",
    "\n",
    "print(f\"Final data shape: {df_data.shape}\")\n",
    "\n",
    "y = df_data[target].values.ravel()\n",
    "if target == [\"SEX_ID (1=m, 2=f)\"]:\n",
    "    y = np.where(y == 2, 0, 1)  # Put the classes as 0 and 1\n",
    "\n",
    "X = df_data.loc[:, columns_features].values  # only brain features\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "random_state = 42\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, shuffle=True, random_state=random_state\n",
    ")\n",
    "# Check size of data\n",
    "print(\"X shape\", X.shape)\n",
    "print(\"y shape\", y.shape)\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcc305",
   "metadata": {},
   "source": [
    "#  Leakage example 1:\n",
    "### Train on whole data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model on the whole data (Fig. 2 in Sasse et al., 2025)\n",
    "dt_raw_lkg1 = RandomForestClassifier(max_depth=10, random_state=random_state)\n",
    "dt_raw_lkg1.fit(X, y)\n",
    "\n",
    "print(\"Raw Data - Train accuracy:\", dt_raw_lkg1.score(X, y))\n",
    "print(\"Raw Data - Test accuracy:\", dt_raw_lkg1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466d8c2",
   "metadata": {},
   "source": [
    "### Correct procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our model on the train set and test on the test set\n",
    "dt_raw = RandomForestClassifier(max_depth=10, random_state=random_state)\n",
    "dt_raw.fit(X_train, y_train)\n",
    "\n",
    "print(\"Raw Data - Train accuracy:\", dt_raw.score(X_train, y_train))\n",
    "print(\"Raw Data - Test accuracy:\", dt_raw.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089d942",
   "metadata": {},
   "source": [
    "When the model was trained in train set and tested on test set the test performance dropped.\n",
    "When the model was trained in the whole dataset it performed well in both, train and test datasets. \n",
    "This is because the model learned patterns of the test set during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92059b32",
   "metadata": {},
   "source": [
    "# Leakage example 2:\n",
    "### Feature selection on whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a95ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define reproducible cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Feature selection on entire dataset (leakage)\n",
    "n_components = 7\n",
    "selector = PCA(n_components=n_components)\n",
    "\n",
    "X_selected_leak = selector.fit_transform(X.copy(), y)\n",
    "\n",
    "# Scale and reduce dimensionality on entire dataset (leakage)\n",
    "scaler = StandardScaler()\n",
    "X_scaled_leak = scaler.fit_transform(X_selected_leak)\n",
    "\n",
    "# Evaluate using fixed CV\n",
    "model = DecisionTreeClassifier(max_depth=10, random_state=random_state)\n",
    "scores_leakage = []\n",
    "for train, test in cv.split(X, y):\n",
    "    model.fit(X_scaled_leak[train, :], y[train])\n",
    "    pred = model.predict(X_scaled_leak[test, :])\n",
    "    scores_leakage.append(roc_auc_score(y[test], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b6b48",
   "metadata": {},
   "source": [
    "### Correct procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with feature selection inside each fold\n",
    "selector = PCA(n_components=n_components)\n",
    "scaler = StandardScaler()\n",
    "model = DecisionTreeClassifier(max_depth=10, random_state=random_state)\n",
    "\n",
    "scores_no_leakage = []\n",
    "\n",
    "for train, test in cv.split(X, y):\n",
    "    X_train = X[train, :]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test, :]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    # Scale and reduce dimensionality on entire dataset (leakage)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit feature selector\n",
    "    X_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "\n",
    "    # Fit ML model\n",
    "    model.fit(X_selected, y_train)\n",
    "\n",
    "    pred = model.predict(X_test_selected)\n",
    "    scores_no_leakage.append(roc_auc_score(y[test], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4817ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Compare Results ==========\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Fold\": np.arange(1, 6),\n",
    "        \"Accuracy with Leakage\": scores_leakage,\n",
    "        \"Accuracy without Leakage\": scores_no_leakage,\n",
    "        \"Difference\": np.array(scores_leakage) - np.array(scores_no_leakage),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results_df)\n",
    "print(\"\\nMean Accuracy with Leakage: \", round(np.mean(scores_leakage)*100, 4))\n",
    "print(\"Mean Accuracy without Leakage: \", round(np.mean(scores_no_leakage)*100, 4))\n",
    "print(\"Mean Difference: \", round(np.mean(results_df[\"Difference\"]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619964c3",
   "metadata": {},
   "source": [
    "The approach causing leakage generally yielded better performance than the correct approach. Even though in this example the effect of leakage is not huge, in bigger and complex datasets its effect is much severe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19ac4d",
   "metadata": {},
   "source": [
    "It is important to note that the results and the effect of leakage might change based on the use of different models, seeds, samples, features, etc.\n",
    "Also leakage is complex and it is often unclear where it might or might not show. However, it is always important to avoid it in order to yield valid estimations of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3666b",
   "metadata": {},
   "source": [
    "# To do!\n",
    "Lets try another model, another pre-processing, or even random seeds to see the effect of the data leakage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FZJ_collaborations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

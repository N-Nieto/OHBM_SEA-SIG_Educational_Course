{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802beeac",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/N-Nieto/OHBM_SEA-SIG_Educational_Course/blob/master/03_pitfalls/03_03_imbalance_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302db54a",
   "metadata": {},
   "source": [
    "# Imbalance learning: Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bf46a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # Ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99203b7",
   "metadata": {},
   "source": [
    "### Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Features: Cortical + Subcortical\n",
    "features = [\"cortical\", \"subcortical\"]\n",
    "\n",
    "# Target: Sex\n",
    "target = [\"SEX_ID (1=m, 2=f)\"]\n",
    "# Confounding variables: No for this example\n",
    "confounding = []\n",
    "\n",
    "data_path = Path(\"../data/\")\n",
    "df_data = pd.read_csv(data_path / \"cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "columns_features = []\n",
    "for feature in features:\n",
    "    if feature == \"cortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path / \"cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    elif feature == \"subcortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path\n",
    "            / \"cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    else:\n",
    "        print(\"feature not recognized\")\n",
    "\n",
    "    df_data = df_data.join(df_feature, how=\"inner\")\n",
    "    columns_features = columns_features + df_feature.columns.to_list()\n",
    "\n",
    "\n",
    "print(f\"Initial data shape: {df_data.shape}\")\n",
    "\n",
    "# Check for NaNs in confounding columns\n",
    "confounding_cols = target + confounding\n",
    "for col in confounding_cols:\n",
    "    if df_data[col].isna().sum() > 0:\n",
    "        print(f\"{df_data[col].isna().sum()} NaNs in column {col}.\")\n",
    "        print(\"Drop NaNs and align subjects\")\n",
    "\n",
    "        # Drop NaNs from the brain dataframe (which contains all columns)\n",
    "        df_data = df_data.dropna(subset=[col])\n",
    "        print(f\"New data shape: {df_data.shape}\")\n",
    "    else:\n",
    "        print(f\"No NaNs in column {col}.\")\n",
    "\n",
    "print(f\"Final data shape: {df_data.shape}\")\n",
    "\n",
    "y = df_data[target].values.ravel()\n",
    "if target == [\"SEX_ID (1=m, 2=f)\"]:\n",
    "    y = np.where(y == 2, 0, 1)  # 1\n",
    "\n",
    "\n",
    "X = df_data.loc[:, columns_features].values  # only brain features\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40962b93",
   "metadata": {},
   "source": [
    "### Forcing Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force imbalance in the dataset\n",
    "imbalance_ratio = 0.15  # Minority class will be 10% of majority class\n",
    "X_minority = X[y == 0]\n",
    "y_minority = y[y == 0]\n",
    "X_majority = X[y == 1][: int(imbalance_ratio * len(X_minority))]\n",
    "y_majority = y[y == 1][\n",
    "    : int(imbalance_ratio * len(X_minority))\n",
    "]  # Keep only 10% of majority class\n",
    "X = np.vstack((X_minority, X_majority))\n",
    "y = np.hstack((y_minority, y_majority))\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n",
    "print(\"Target distribution\")\n",
    "print(y.sum(), len(y) - y.sum())\n",
    "print(f\"Imbalance ratio: {y.sum() / len(y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e67b22",
   "metadata": {},
   "source": [
    "## Training a ML model and plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ae350",
   "metadata": {},
   "source": [
    "## Looks great, doesn't it?!\n",
    "\n",
    "### Let's now take a look at our confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1498d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b2d8a",
   "metadata": {},
   "source": [
    "# Wait, we clearly have a problem, our classifier is not working well in our minority class!\n",
    "\n",
    "## We need to characterize better our results. Let's calculate more metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317020ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": sensitivity_specificity_support(y_test, y_pred)[0][0],\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightgreen\",\n",
    "        \"salmon\",\n",
    "        \"orange\",\n",
    "        \"purple\",\n",
    "        \"lightcoral\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f9b2b",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "What is your take from the metrics?\n",
    "\n",
    "We should always report several metrics, to better understand the models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be05f8",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73845674",
   "metadata": {},
   "source": [
    "# Threshold ajustment\n",
    "\n",
    "## By default, sklearn prediction use a threshold of 0.5, but we could aproximate a better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probabilities again\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Adjust threshold based on class imbalance\n",
    "# this is an approximation of the optimal threshold in terms of balanced accuracy\n",
    "thd = y.sum() / len(y)\n",
    "\n",
    "# Get new predictions using the adjusted threshold\n",
    "y_pred = y_proba >= thd\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": sensitivity_specificity_support(y_test, y_pred)[0][0],\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightgreen\",\n",
    "        \"salmon\",\n",
    "        \"orange\",\n",
    "        \"purple\",\n",
    "        \"lightcoral\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8e11f",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "What can you observe? How is the relationship between ACC and Balanced ACC now?\n",
    "\n",
    "Did AUC change? Why, why not?\n",
    "\n",
    "We improved our performance on the minority class, but at what cost?\n",
    "\n",
    "The decision of which type of error is more critical is problem dependant, you as the expert, will have to take this decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c33046",
   "metadata": {},
   "source": [
    "So far, we did not change the model itself, only treated differently the predictions that the model made.\n",
    "In the next notebook, we will explore particular techniques to deal with imbalance problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FZJ_collaborations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

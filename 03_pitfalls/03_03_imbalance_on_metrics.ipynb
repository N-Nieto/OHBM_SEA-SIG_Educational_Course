{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802beeac",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/N-Nieto/OHBM_SEA-SIG_Educational_Course/blob/master/03_pitfalls/03_03_imbalance_on_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3ae4c",
   "metadata": {},
   "source": [
    "### If you are running in Google Colab, uncomment the cell below to load the data.\n",
    "### If you are running locally, ignore the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87ef059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from urllib.request import urlretrieve\n",
    "# # Clean files\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Download necessary data files\n",
    "# Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# # 01_basic_ML.ipynb needs this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_IXI_behavioural.csv?download=1', './data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # 02_XAI.ipynb needs also this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# # Load data\n",
    "# df_behav = pd.read_csv(\"data/cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "\n",
    "# # Some height values are not sensible, we filter them out\n",
    "# height = df_behav[\"HEIGHT\"].values\n",
    "# df_behav = df_behav[np.logical_and(height > 120, height < 200)]\n",
    "\n",
    "# # Remove NaNs and duplicates\n",
    "# df_behav.dropna(inplace=True)\n",
    "# df_behav.drop_duplicates(keep='first', inplace=True)\n",
    "# df_behav.to_csv('data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_cortical_100 = pd.read_csv(\"data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\", index_col=0)\n",
    "# df_cortical_100.dropna(inplace=True)\n",
    "# df_cortical_100.to_csv('data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_subcortical = pd.read_csv(\"data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\", index_col=0)\n",
    "# df_subcortical.dropna(inplace=True)\n",
    "# df_subcortical.to_csv('data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# data_path = Path(\"data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302db54a",
   "metadata": {},
   "source": [
    "# Imbalance learning: Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bf46a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # Ignore\n",
    "\n",
    "if 'data_path' not in locals():\n",
    "    data_path = Path(\"../data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99203b7",
   "metadata": {},
   "source": [
    "### Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Features: Cortical + Subcortical\n",
    "features = [\"cortical\", \"subcortical\"]\n",
    "\n",
    "# Target: Sex\n",
    "target = [\"SEX_ID (1=m, 2=f)\"]\n",
    "# Confounding variables: No for this example\n",
    "confounding = []\n",
    "\n",
    "df_data = pd.read_csv(data_path / \"cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "columns_features = []\n",
    "for feature in features:\n",
    "    if feature == \"cortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path / \"cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    elif feature == \"subcortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path\n",
    "            / \"cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    else:\n",
    "        print(\"feature not recognized\")\n",
    "\n",
    "    df_data = df_data.join(df_feature, how=\"inner\")\n",
    "    columns_features = columns_features + df_feature.columns.to_list()\n",
    "\n",
    "print(f\"Final data shape: {df_data.shape}\")\n",
    "\n",
    "y = df_data[target].values.ravel()\n",
    "if target == [\"SEX_ID (1=m, 2=f)\"]:\n",
    "    y = np.where(y == 2, 0, 1)  # Put the classes as 0 and 1\n",
    "\n",
    "X = df_data.loc[:, columns_features].values  # only brain features\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40962b93",
   "metadata": {},
   "source": [
    "### Forcing Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force imbalance in the dataset\n",
    "imbalance_ratio = 0.15  # Minority class will be 15% of majority class\n",
    "X_minority = X[y == 0]\n",
    "y_minority = y[y == 0]\n",
    "X_majority = X[y == 1][: int(imbalance_ratio * len(X_minority))]\n",
    "y_majority = y[y == 1][: int(imbalance_ratio * len(X_minority))]  # Keep only 15% of majority class\n",
    "X = np.vstack((X_minority, X_majority))\n",
    "y = np.hstack((y_minority, y_majority))\n",
    "\n",
    "print(\"X shape after imbalance\")\n",
    "print(X.shape)\n",
    "print(\"Target distribution\")\n",
    "print(y.sum(), len(y) - y.sum())\n",
    "print(f\"Imbalance ratio: {y.sum() / len(y):.2f}\")\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.3\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e67b22",
   "metadata": {},
   "source": [
    "## Training a ML model and plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ae350",
   "metadata": {},
   "source": [
    "## Looks great, doesn't it?!\n",
    "\n",
    "### Let's now take a look at our confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1498d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b2d8a",
   "metadata": {},
   "source": [
    "# Wait, we clearly have a problem, our classifier is not working well in our minority class!\n",
    "\n",
    "## We need to characterize better our results. Let's calculate more metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317020ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightgreen\",\n",
    "        \"salmon\",\n",
    "        \"orange\",\n",
    "        \"purple\",\n",
    "        \"lightcoral\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f9b2b",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "What is your take from the metrics?\n",
    "\n",
    "We should always report several metrics, to better understand the models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be05f8",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73845674",
   "metadata": {},
   "source": [
    "# Threshold ajustment\n",
    "\n",
    "## By default, sklearn prediction use a threshold of 0.5, but we could aproximate a better threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probabilities again\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Adjust threshold based on class imbalance\n",
    "# this is an approximation of the optimal threshold in terms of balanced accuracy\n",
    "thd = y.sum() / len(y)\n",
    "\n",
    "# Get new predictions using the adjusted threshold\n",
    "y_pred = y_proba >= thd\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightgreen\",\n",
    "        \"salmon\",\n",
    "        \"orange\",\n",
    "        \"purple\",\n",
    "        \"lightcoral\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8e11f",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "What can you observe? How is the relationship between ACC and Balanced ACC now?\n",
    "\n",
    "Did AUC change? Why, why not?\n",
    "\n",
    "We improved our performance on the minority class, but at what cost?\n",
    "\n",
    "The decision of which type of error is more critical is problem dependant, you as the expert, will have to take this decision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FZJ_collaborations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

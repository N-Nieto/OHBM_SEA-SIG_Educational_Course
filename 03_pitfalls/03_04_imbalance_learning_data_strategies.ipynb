{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802beeac",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/N-Nieto/OHBM_SEA-SIG_Educational_Course/blob/master/03_pitfalls/03_04_imbalance_learning_data_strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2c6d6",
   "metadata": {},
   "source": [
    "### If you are running in Google Colab, uncomment the cell below to load the data.\n",
    "### If you are running locally, ignore the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba02f8",
   "metadata": {},
   "source": [
    "For questions on this notebook contact: n.nieto@fz-juelich.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from urllib.request import urlretrieve\n",
    "# # Clean files\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Download necessary data files\n",
    "# Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# # 01_basic_ML.ipynb needs this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_IXI_behavioural.csv?download=1', './data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # 02_XAI.ipynb needs also this files\n",
    "# urlretrieve('https://zenodo.org/records/17056022/files/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv?download=1', './data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# # Load data\n",
    "# df_behav = pd.read_csv(\"data/cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "\n",
    "# # Some height values are not sensible, we filter them out\n",
    "# height = df_behav[\"HEIGHT\"].values\n",
    "# df_behav = df_behav[np.logical_and(height > 120, height < 200)]\n",
    "\n",
    "# # Remove NaNs and duplicates\n",
    "# df_behav.dropna(inplace=True)\n",
    "# df_behav.drop_duplicates(keep='first', inplace=True)\n",
    "# df_behav.to_csv('data/cleaned_IXI_behavioural.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_cortical_100 = pd.read_csv(\"data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\", index_col=0)\n",
    "# df_cortical_100.dropna(inplace=True)\n",
    "# df_cortical_100.to_csv('data/cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv')\n",
    "\n",
    "# # Remove NaNs\n",
    "# df_subcortical = pd.read_csv(\"data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\", index_col=0)\n",
    "# df_subcortical.dropna(inplace=True)\n",
    "# df_subcortical.to_csv('data/cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv')\n",
    "\n",
    "# data_path = Path(\"data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302db54a",
   "metadata": {},
   "source": [
    "# Imbalance learning: Data strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bf46a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # Ignore\n",
    "\n",
    "if 'data_path' not in locals():\n",
    "    data_path = Path(\"../data/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99203b7",
   "metadata": {},
   "source": [
    "### Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Features: Cortical + Subcortical\n",
    "features = [\"cortical\", \"subcortical\"]\n",
    "\n",
    "# Target: Sex\n",
    "target = [\"SEX_ID (1=m, 2=f)\"]\n",
    "# Confounding variables: No for this example\n",
    "confounding = []\n",
    "\n",
    "df_data = pd.read_csv(data_path / \"cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "columns_features = []\n",
    "for feature in features:\n",
    "    if feature == \"cortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path / \"cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    elif feature == \"subcortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path\n",
    "            / \"cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    else:\n",
    "        print(\"feature not recognized\")\n",
    "\n",
    "    df_data = df_data.join(df_feature, how=\"inner\")\n",
    "    columns_features = columns_features + df_feature.columns.to_list()\n",
    "\n",
    "print(f\"Final data shape: {df_data.shape}\")\n",
    "\n",
    "y = df_data[target].values.ravel()\n",
    "if target == [\"SEX_ID (1=m, 2=f)\"]:\n",
    "    y = np.where(y == 2, 0, 1)  # Put the classes as 0 and 1\n",
    "\n",
    "X = df_data.loc[:, columns_features].values  # only brain features\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40962b93",
   "metadata": {},
   "source": [
    "### Forcing Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force imbalance in the dataset\n",
    "imbalance_ratio = 0.15  # Minority class will be 15% of majority class\n",
    "X_minority = X[y == 0]\n",
    "y_minority = y[y == 0]\n",
    "X_majority = X[y == 1][: int(imbalance_ratio * len(X_minority))]\n",
    "y_majority = y[y == 1][: int(imbalance_ratio * len(X_minority))]  # Keep only 15% of majority class\n",
    "X = np.vstack((X_minority, X_majority))\n",
    "y = np.hstack((y_minority, y_majority))\n",
    "\n",
    "print(\"X shape after imbalance\")\n",
    "print(X.shape)\n",
    "print(\"Target distribution\")\n",
    "print(y.sum(), len(y) - y.sum())\n",
    "print(f\"Imbalance ratio: {y.sum() / len(y):.2f}\")\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.3\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e67b22",
   "metadata": {},
   "source": [
    "## Training a ML model and plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightgreen\",\n",
    "        \"salmon\",\n",
    "        \"orange\",\n",
    "        \"purple\",\n",
    "        \"lightcoral\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1498d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b2d8a",
   "metadata": {},
   "source": [
    "# Until here, we have the same as before, let's explore data strategies to mitigate the class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0973e76",
   "metadata": {},
   "source": [
    "# Oversampling Minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf8113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Random oversampling of minority class\n",
    "ros = RandomOverSampler(random_state=23, shrinkage= 0.1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train on resampled data\n",
    "model_ros = LogisticRegression(max_iter=1000)\n",
    "model_ros.fit(X_resampled, y_resampled)\n",
    "y_pred = model_ros.predict(X_test)\n",
    "y_proba = model_ros.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics after resampling\n",
    "metrics_ros = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "# Random oversampling of minority class\n",
    "smote = SMOTE(random_state=23)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train on resampled data\n",
    "model_smote = LogisticRegression(max_iter=1000)\n",
    "model_smote.fit(X_resampled, y_resampled)\n",
    "y_pred = model_smote.predict(X_test)\n",
    "y_proba = model_smote.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics after resampling\n",
    "metrics_smote = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fa4ac",
   "metadata": {},
   "source": [
    "## Lets plot and compare several metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32655965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\"Original\": metrics, \"Random Oversampling\": metrics_ros, \"SMOTE\": metrics_smote}\n",
    ")\n",
    "\n",
    "# Plot comparison - one metric per subplot\n",
    "metrics_list = list(metrics.keys())\n",
    "n_metrics = len(metrics_list)\n",
    "\n",
    "# Alternative: Single plot with all metrics grouped by method\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(metrics_list))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(\n",
    "    x - width,\n",
    "    [metrics[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Original\",\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "bars2 = ax.bar(\n",
    "    x,\n",
    "    [metrics_ros[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Random Oversampling\",\n",
    "    color=\"lightgreen\",\n",
    ")\n",
    "bars3 = ax.bar(\n",
    "    x + width,\n",
    "    [metrics_smote[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"SMOTE\",\n",
    "    color=\"salmon\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\n",
    "    \"Performance Metrics Comparison Across Different Oversampling Methods\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_list, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "\n",
    "# Add value labels on top of bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 0.01,\n",
    "            f\"{height:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "\n",
    "add_labels(bars1)\n",
    "add_labels(bars2)\n",
    "add_labels(bars3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0356e8e",
   "metadata": {},
   "source": [
    "## Confusion matrix for oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix comparison\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 5))\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_title(\"Original\")\n",
    "ConfusionMatrixDisplay.from_estimator(model_ros, X_test, y_test, ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_title(\"After Oversampling RandomOverSampler\")\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    model_smote, X_test, y_test, ax=ax[2], cmap=\"Blues\"\n",
    ")\n",
    "ax[2].set_title(\"After Oversampling SMOTE\")\n",
    "ax[0].figure.suptitle(\"Confusion Matrix Comparison\", fontsize=16, fontweight=\"bold\")\n",
    "# Remove the color bar from all confusion matrix plots\n",
    "for axes in ax:\n",
    "    if hasattr(axes, \"images\") and axes.images:\n",
    "        for im in axes.images:\n",
    "            if im.colorbar:\n",
    "                im.colorbar.remove()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da404de3",
   "metadata": {},
   "source": [
    "# Undersample Majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "\n",
    "# Random undersampling of majority class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train on undersampled data\n",
    "model_rus = LogisticRegression(max_iter=1000)\n",
    "model_rus.fit(X_undersampled, y_undersampled)\n",
    "y_pred = model_rus.predict(X_test)\n",
    "y_proba = model_rus.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics after undersampling\n",
    "metrics_rus = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# NearMiss of majority class\n",
    "NM = NearMiss()\n",
    "X_undersampled, y_undersampled = NM.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train on undersampled data\n",
    "model_nm = LogisticRegression(max_iter=1000)\n",
    "model_nm.fit(X_undersampled, y_undersampled)\n",
    "y_pred = model_nm.predict(X_test)\n",
    "y_proba = model_nm.predict_proba(X_test)[:, 1]\n",
    "# Calculate metrics after undersampling\n",
    "metrics_nm = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\"Original\": metrics, \"Random Undersampling\": metrics_rus, \"NearMiss\": metrics_nm}\n",
    ")\n",
    "\n",
    "# Plot comparison - one metric per subplot\n",
    "metrics_list = list(metrics.keys())\n",
    "n_metrics = len(metrics_list)\n",
    "\n",
    "# Alternative: Single plot with all metrics grouped by method\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(metrics_list))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(\n",
    "    x - width,\n",
    "    [metrics[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Original\",\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "bars2 = ax.bar(\n",
    "    x,\n",
    "    [metrics_rus[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Random Undersampling\",\n",
    "    color=\"lightgreen\",\n",
    ")\n",
    "bars3 = ax.bar(\n",
    "    x + width,\n",
    "    [metrics_nm[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"NearMiss\",\n",
    "    color=\"salmon\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\n",
    "    \"Performance Metrics Comparison Across Different Undersampling Methods\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_list, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "\n",
    "# Add value labels on top of bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 0.01,\n",
    "            f\"{height:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "\n",
    "add_labels(bars1)\n",
    "add_labels(bars2)\n",
    "add_labels(bars3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b92c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix comparison\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 5))\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_title(\"Original\")\n",
    "ConfusionMatrixDisplay.from_estimator(model_rus, X_test, y_test, ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_title(\"Random Undersampling\")\n",
    "ConfusionMatrixDisplay.from_estimator(model_nm, X_test, y_test, ax=ax[2], cmap=\"Blues\")\n",
    "ax[2].set_title(\"NearMiss\")\n",
    "plt.tight_layout()\n",
    "# Remove the color bar from all confusion matrix plots\n",
    "for axes in ax:\n",
    "    if hasattr(axes, \"images\") and axes.images:\n",
    "        for im in axes.images:\n",
    "            if im.colorbar:\n",
    "                im.colorbar.remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64cd67",
   "metadata": {},
   "source": [
    "# We can combine the upsampling and downsampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# Combined method SMOTE + ENN\n",
    "smote_eenn = SMOTEENN(random_state=42)\n",
    "X_undersampled, y_undersampled = smote_eenn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train on undersampled data\n",
    "model_smote_eenn = LogisticRegression(max_iter=1000)\n",
    "model_smote_eenn.fit(X_undersampled, y_undersampled)\n",
    "y_pred = model_smote_eenn.predict(X_test)\n",
    "y_proba = model_smote_eenn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics after undersampling\n",
    "metrics_smote_eenn = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "# Combined method SMOTE + ENN\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_undersampled, y_undersampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train on undersampled data\n",
    "model_smote_tomek = LogisticRegression(max_iter=1000)\n",
    "model_smote_tomek.fit(X_undersampled, y_undersampled)\n",
    "y_pred = model_smote_tomek.predict(X_test)\n",
    "y_proba = model_smote_tomek.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics after undersampling\n",
    "metrics_smote_tomek = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": specificity_score(y_test, y_pred),\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\"Original\": metrics, \"SMOTEENN\": metrics_smote_eenn, \"Smote Tomek\": metrics_smote_tomek}\n",
    ")\n",
    "\n",
    "# Plot comparison - one metric per subplot\n",
    "metrics_list = list(metrics.keys())\n",
    "n_metrics = len(metrics_list)\n",
    "\n",
    "# Alternative: Single plot with all metrics grouped by method\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(metrics_list))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(\n",
    "    x - width,\n",
    "    [metrics[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Original\",\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "bars2 = ax.bar(\n",
    "    x,\n",
    "    [metrics_smote_eenn[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"SMOTEENN\",\n",
    "    color=\"lightgreen\",\n",
    ")\n",
    "bars3 = ax.bar(\n",
    "    x + width,\n",
    "    [metrics_smote_tomek[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Smote Tomek\",\n",
    "    color=\"salmon\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\n",
    "    \"Performance Metrics Comparison Across Different Undersampling Methods\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_list, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "\n",
    "# Add value labels on top of bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 0.01,\n",
    "            f\"{height:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "\n",
    "add_labels(bars1)\n",
    "add_labels(bars2)\n",
    "add_labels(bars3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7030472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix comparison\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 5))\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_title(\"Original\")\n",
    "ConfusionMatrixDisplay.from_estimator(model_smote_eenn, X_test, y_test, ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_title(\"SmoteENN\")\n",
    "ConfusionMatrixDisplay.from_estimator(model_smote_tomek, X_test, y_test, ax=ax[2], cmap=\"Blues\")\n",
    "ax[2].set_title(\"Smote Tomek\")\n",
    "plt.tight_layout()\n",
    "# Remove the color bar from all confusion matrix plots\n",
    "for axes in ax:\n",
    "    if hasattr(axes, \"images\") and axes.images:\n",
    "        for im in axes.images:\n",
    "            if im.colorbar:\n",
    "                im.colorbar.remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f2a4d",
   "metadata": {},
   "source": [
    "# To do!\n",
    "\n",
    "### Combine other two sampling strategies and plot the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FZJ_collaborations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

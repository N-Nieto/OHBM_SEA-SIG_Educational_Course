{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802beeac",
   "metadata": {},
   "source": [
    "<a   href=\"https://colab.research.google.com/github/N-Nieto/OHBM_SEA-SIG_Educational_Course/blob/master/03_pitfalls/03_03_imbalance_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302db54a",
   "metadata": {},
   "source": [
    "# Imbalance learning: Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60bf46a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # Ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99203b7",
   "metadata": {},
   "source": [
    "### Data loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Features: Cortical + Subcortical\n",
    "features = [\"cortical\", \"subcortical\"]\n",
    "\n",
    "# Target: Sex\n",
    "target = [\"SEX_ID (1=m, 2=f)\"]\n",
    "# Confounding variables: No for this example\n",
    "confounding = []\n",
    "\n",
    "data_path = Path(\"../data/\")\n",
    "df_data = pd.read_csv(data_path / \"cleaned_IXI_behavioural.csv\", index_col=0)\n",
    "columns_features = []\n",
    "for feature in features:\n",
    "    if feature == \"cortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path / \"cleaned_VBM_GM_Schaefer100x17_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    elif feature == \"subcortical\":\n",
    "        df_feature = pd.read_csv(\n",
    "            data_path\n",
    "            / \"cleaned_VBM_GM_TianxS1x3TxMNI6thgeneration_mean_aggregation.csv\",\n",
    "            index_col=0,\n",
    "        )\n",
    "    else:\n",
    "        print(\"feature not recognized\")\n",
    "\n",
    "    df_data = df_data.join(df_feature, how=\"inner\")\n",
    "    columns_features = columns_features + df_feature.columns.to_list()\n",
    "\n",
    "\n",
    "print(f\"Initial data shape: {df_data.shape}\")\n",
    "\n",
    "# Check for NaNs in confounding columns\n",
    "confounding_cols = target + confounding\n",
    "for col in confounding_cols:\n",
    "    if df_data[col].isna().sum() > 0:\n",
    "        print(f\"{df_data[col].isna().sum()} NaNs in column {col}.\")\n",
    "        print(\"Drop NaNs and align subjects\")\n",
    "\n",
    "        # Drop NaNs from the brain dataframe (which contains all columns)\n",
    "        df_data = df_data.dropna(subset=[col])\n",
    "        print(f\"New data shape: {df_data.shape}\")\n",
    "    else:\n",
    "        print(f\"No NaNs in column {col}.\")\n",
    "\n",
    "print(f\"Final data shape: {df_data.shape}\")\n",
    "\n",
    "y = df_data[target].values.ravel()\n",
    "if target == [\"SEX_ID (1=m, 2=f)\"]:\n",
    "    y = np.where(y == 2, 0, 1)  # 1\n",
    "\n",
    "\n",
    "X = df_data.loc[:, columns_features].values  # only brain features\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40962b93",
   "metadata": {},
   "source": [
    "### Forcing Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force imbalance in the dataset\n",
    "imbalance_ratio = 0.15  # Minority class will be 10% of majority class\n",
    "X_minority = X[y == 0]\n",
    "y_minority = y[y == 0]\n",
    "X_majority = X[y == 1][: int(imbalance_ratio * len(X_minority))]\n",
    "y_majority = y[y == 1][\n",
    "    : int(imbalance_ratio * len(X_minority))\n",
    "]  # Keep only 10% of majority class\n",
    "X = np.vstack((X_minority, X_majority))\n",
    "y = np.hstack((y_minority, y_majority))\n",
    "\n",
    "print(\"X shape\")\n",
    "print(X.shape)\n",
    "print(\"Target distribution\")\n",
    "print(y.sum(), len(y) - y.sum())\n",
    "print(f\"Imbalance ratio: {y.sum()/len(y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e67b22",
   "metadata": {},
   "source": [
    "## Training a ML model and plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1\": f1_score(y_test, y_pred),\n",
    "    \"Specificity\": sensitivity_specificity_support(y_test, y_pred)[0][0],\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
    "}\n",
    "\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.bar(\n",
    "    metrics.keys(),\n",
    "    metrics.values(),\n",
    "    color=[\n",
    "        \"skyblue\",\n",
    "        \"lightgreen\",\n",
    "        \"salmon\",\n",
    "        \"orange\",\n",
    "        \"purple\",\n",
    "        \"lightcoral\",\n",
    "        \"lightseagreen\",\n",
    "    ],\n",
    ")\n",
    "plt.title(\"Model Performance Metrics on Imbalanced Data\")\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.ylabel(\"Score\")\n",
    "for i, v in enumerate(metrics.values()):\n",
    "    plt.text(i, v + 0.05, f\"{v:.3f}\", ha=\"center\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1498d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75647f47",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd57823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "# Using class weighting\n",
    "model_weighted = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "model_weighted.fit(X_train, y_train)\n",
    "y_pred_weighted = model_weighted.predict(X_test)\n",
    "\n",
    "# Calculate metrics with class weighting\n",
    "metrics_weighted = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_weighted),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred_weighted),\n",
    "    \"Recall\": recall_score(y_test, y_pred_weighted),\n",
    "    \"F1\": f1_score(y_test, y_pred_weighted),\n",
    "    \"Specificity\": sensitivity_specificity_support(y_test, y_pred_weighted)[0][0],\n",
    "    \"ROC AUC\": roc_auc_score(y_test, model_weighted.predict_proba(X_test)[:, 1]),\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Train BalancedRandomForest on original imbalanced data\n",
    "brf = BalancedRandomForestClassifier(n_estimators=10, random_state=42)\n",
    "brf.fit(X_train, y_train)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "y_proba_brf = brf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics for BalancedRandomForest\n",
    "metrics_brf = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_brf),\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred_brf),\n",
    "    \"Recall\": recall_score(y_test, y_pred_brf),\n",
    "    \"F1\": f1_score(y_test, y_pred_brf),\n",
    "    \"Specificity\": sensitivity_specificity_support(y_test, y_pred_brf)[0][0],\n",
    "    \"ROC AUC\": roc_auc_score(y_test, y_proba_brf),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b63ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\"Original\": metrics, \"Balanced LG\": metrics_weighted, \"Balanced RF\": metrics_brf}\n",
    ")\n",
    "\n",
    "# Plot comparison - one metric per subplot\n",
    "metrics_list = list(metrics.keys())\n",
    "n_metrics = len(metrics_list)\n",
    "\n",
    "# Alternative: Single plot with all metrics grouped by method\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(metrics_list))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(\n",
    "    x - width,\n",
    "    [metrics[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Original\",\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "bars2 = ax.bar(\n",
    "    x,\n",
    "    [metrics_weighted[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Balanced LG\",\n",
    "    color=\"lightgreen\",\n",
    ")\n",
    "bars3 = ax.bar(\n",
    "    x + width,\n",
    "    [metrics_brf[m] for m in metrics_list],\n",
    "    width,\n",
    "    label=\"Balanced RF\",\n",
    "    color=\"salmon\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Metrics\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\n",
    "    \"Performance Metrics Comparison Across Different Oversampling Methods\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_list, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "\n",
    "# Add value labels on top of bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 0.01,\n",
    "            f\"{height:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "\n",
    "add_labels(bars1)\n",
    "add_labels(bars2)\n",
    "add_labels(bars3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153066df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix comparison\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 5))\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_title(\"Original (LG)\")\n",
    "ConfusionMatrixDisplay.from_estimator(model_weighted, X_test, y_test, ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_title(\"Balanced Logistic Regression\")\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    brf, X_test, y_test, ax=ax[2], cmap=\"Blues\"\n",
    ")\n",
    "ax[2].set_title(\"Balanced Random Forest\")\n",
    "ax[0].figure.suptitle(\"Confusion Matrix Comparison\", fontsize=16, fontweight=\"bold\")\n",
    "# Remove the color bar from all confusion matrix plots\n",
    "for axes in ax:\n",
    "    if hasattr(axes, \"images\") and axes.images:\n",
    "        for im in axes.images:\n",
    "            if im.colorbar:\n",
    "                im.colorbar.remove()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FZJ_collaborations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
